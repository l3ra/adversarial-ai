wandb: Currently logged in as: bfhwulr (bfhwulr-renl). Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.3
wandb: Run data is saved locally in /Users/leraleonteva/Documents/adversarial-ai/gcp-models/wandb/run-20250122_182833-aifotkkj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-microwave-106
wandb: ‚≠êÔ∏è View project at https://wandb.ai/bfhwulr-renl/llm-pgd
wandb: üöÄ View run at https://wandb.ai/bfhwulr-renl/llm-pgd/runs/aifotkkj
[+] Running 100 iterations ... 
Sending chunk 1/1 with shape 40, 128256
Attempt 1/3 failed: Remote model inference failed for chunk 0: 
<html><head>
<meta http-equiv="content-type" content="text/html;charset=utf-8">
<title>502 Server Error</title>
</head>
<body text=#000000 bgcolor=#ffffff>
<h1>Error: Server Error</h1>
<h2>The server encountered a temporary error and could not complete your request.<p>Please try again in 30 seconds.</h2>
<h2></h2>
</body></html>

Sending chunk 1/1 with shape 40, 128256
[1] No gradients computed for inputs. Skipping to next iteration.
Sending chunk 1/1 with shape 40, 128256
[2] No gradients computed for inputs. Skipping to next iteration.
Sending chunk 1/1 with shape 40, 128256
Traceback (most recent call last):
  File "/Users/leraleonteva/Documents/adversarial-ai/gcp-models/../PGD_pgd/pgd remote attack llama 1B.py", line 533, in <module>
    main(CLI(Config, as_positional=False))
  File "/Users/leraleonteva/Documents/adversarial-ai/gcp-models/../PGD_pgd/pgd remote attack llama 1B.py", line 526, in main
    loss = attack(fabric, model, tokenizer, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/leraleonteva/Documents/adversarial-ai/gcp-models/../PGD_pgd/pgd remote attack llama 1B.py", line 318, in attack
    logits = forward_relaxed_one_hot_remote_with_retries(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/leraleonteva/Documents/adversarial-ai/gcp-models/../PGD_pgd/pgd remote attack llama 1B.py", line 127, in forward_relaxed_one_hot_remote_with_retries
    logits = forward_relaxed_one_hot_remote(inputs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/leraleonteva/Documents/adversarial-ai/gcp-models/../PGD_pgd/pgd remote attack llama 1B.py", line 152, in forward_relaxed_one_hot_remote
    response = requests.post(REMOTE_MODEL_URL, json=data, stream=True, timeout=120)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/lib/python3.11/site-packages/urllib3/connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py", line 1395, in getresponse
    response.begin()
  File "/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py", line 286, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py", line 718, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py", line 1314, in recv_into
    return self.read(nbytes, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py", line 1166, in read
    return self._sslobj.read(len, buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33msweet-microwave-106[0m at: [34mhttps://wandb.ai/bfhwulr-renl/llm-pgd/runs/aifotkkj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250122_182833-aifotkkj/logs[0m
